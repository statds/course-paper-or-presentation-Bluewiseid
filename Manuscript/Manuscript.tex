\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{lipsum}
\usepackage{setspace}
\usepackage{tikz}
\usepackage{pdfpages}
\usepackage[colorlinks=true, citecolor=blue]{hyperref}
\doublespacing
\title{Machine Learning for Handwriting Recognition: Algorithms and Techniques}
\author{Lai Jiang\\
  University of Connecticut Department of Statistics
}

\begin{document}
\maketitle

\section* {Abstract}
This paper examines the interface between machine learning and handwriting recognition, an area that has grown significantly due to the development of powerful algorithms and sophisticated techniques. Despite the growing popularity of digital communications, handwriting remains a unique expression of personality that poses significant recognition challenges due to its variability and idiosyncrasies. This article explores the role of machine learning of basic concepts, data collection methods, data augmentation techniques, and various algorithmic approaches to handwriting recognition, including traditional machine learning and neural networks. The manuscript also discusses the impact of machine learning on the connection between human interactions and digital systems, highlighting its potential to improve user experience and facilitate digital interactions. By examining methods and advances in the field, this article reveals the future possibilities and applications of machine learning for accurately and efficiently processing handwritten text.

%\section* {Keywords}
%Machine Learning, Deep Learning, Handwriting Recognition, Activation Function, Model, Parameters...

\section* {Introduction}
In an era where digital communication pervades nearly every facet of our lives, the beauty and uniqueness of human handwriting still holds profound significance. From historical manuscripts to personal notes, handwriting offers a glimpse into a person's individuality and emotions. Yet, deciphering diverse handwritten styles and converting them into digital text is a challenging task. The irregularities, variations, and idiosyncrasies present in handwriting have made its recognition one of the most intriguing problems in the realm of pattern recognition and artificial intelligence. However, the evolution of machine learning, with its robust algorithms and sophisticated techniques, has brought groundbreaking advancements to this domain. Handwriting recognition, once a distant dream, is now manifesting in various applications ranging from mail sorting to bank cheque processing and beyond. 

The importance of machine learning in handwriting recognition cannot be overstated, as it stands at the forefront of bridging human interaction with digital systems. This technology plays a crucial role in various applications that significantly impact our daily lives and professional sectors. In the banking industry, it revolutionizes processes by accurately reading handwritten cheques and forms, thus streamlining financial transactions and enhancing security. In the field of education, machine learning algorithms assist in evaluating handwritten exam responses, offering a more efficient grading system while also providing insights into students' learning patterns. Additionally, in historical research, these algorithms are indispensable for digitizing ancient manuscripts and documents, unlocking new realms of knowledge previously inaccessible due to the sheer volume and complexity of handwritten texts. Handwriting recognition also finds its use in personal devices, where it enhances user experience by allowing natural note-taking and communication in users' own handwriting, seamlessly integrating with various languages and scripts. The broad range of these applications not only underscores the versatility and adaptability of machine learning in handwriting recognition but also highlights its potential to transform and facilitate numerous aspects of our digital interactions.This essay delves into the heart of machine learning algorithms and techniques that power handwriting recognition, shedding light on the innovations that bridge the gap between the analog strokes of a pen and the digital bytes of a computer.

\section* {Fundemental Concepts}
In the realm of machine learning, a foundational understanding is crucial for advancing applications such as handwriting recognition. And Since handwriting is process of training in machine learning, or more accurately, in deep learning, We need to figure out, the difference between each algorithm, including CNN, RNN and LSTNs, also, we have to deeply distinguish the supervised and unsupervised learning in machine learning field distinctively.

\paragraph{Basics of Machine Learning}
So what is machine learning? Essentially, machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. This learning process is driven by algorithms that interpret and process data, extract patterns and make decisions. In handwriting recognition, these algorithms play a crucial role in decoding the diversity and complexity of human handwriting. Machine learning can be divided into three main types: supervised learning, where models are trained on labeled data; unsupervised learning, which processes unlabeled data and aims to discover hidden patterns; and reinforcement learning, where models learn through trial and error. Decision-making techniques. Each learning type has a unique impact on handwriting recognition.

\paragraph{Handwriting Recognition Specifics}
Similarly, handwriting is also a process of the training in the field of machine learning. As a specialized application of machine learning, it entails the intricate process of converting handwritten text into a digital format that machines can interpret. This task presents unique challenges, primarily due to the vast variability and individuality inherent in human handwriting. Unlike typed text, handwritten characters and words can vary greatly in size, style, alignment, and stroke thickness, even within a single document. Additionally, cursive handwriting introduces complexities such as connected letters and overlapping strokes, making the task of segmentation and recognition notably challenging. In the context of machine learning, these challenges necessitate sophisticated algorithms capable of handling such variability and ambiguity.

There are two primary modes of handwriting recognition exist: offline and online. Offline recognition involves processing static images of handwritten text, or the image or figure has already been complete, instance like scanned or printed documents and photographs. Under this circumstances, the focus lies in accurately discerning characters and words from a fixed representation, often requiring robust feature extraction and pattern recognition techniques. Online handwriting recognition, in contrast, deals with real-time data. It will translate the words from the scratch that the user made, such as the input from a stylus or digital pen, where the temporal sequence of strokes provides additional context for recognition. This mode can leverage dynamic information like stroke order, pressure, and speed, offering a different dimension of data for machine learning models to analyze.

Futhermore, The sophistication of handwriting recognition systems is further underscored by the need to accommodate diverse handwriting styles, including both print and cursive, as well as the need to be adaptable to multiple languages and scripts, each with its own set of characters and writing rules. Machine learning models in this domain are typically trained on vast data sets containing varied examples of handwriting to enhance their accuracy and generalizability. Pre-processing techniques such as normalization, which adjusts for size and orientation, and noise reduction, which cleans up the image, are crucial steps in preparing the data for these models. The ultimate goal of these systems is to achieve a level of accuracy and efficiency that not only matches human capability but also provides scalable solutions for processing large volumes of handwritten data in various applications, from automated form processing to real-time note translation.

\section* {Data Collection}
When we're dealing with handwriting recognition tasks, choosing the right libraries and packages is crucial to obtain reliable training results. Notable libraries include TensorFlow and Keras, which provide a wealth of deep learning capabilities that are essential for building and training neural networks that can recognize handwritten characters. Additionally, PyTorch is a highly flexible and dynamic open source machine learning framework, particularly known for its easy of using and suitability for a wide range of tasks, including handwriting recognition. It can build, train, and evaluate deep neural networks through a simple Python interface. On the other hand, the MNIST dataset is a classic dataset in the machine learning community, containing 60,000 training images of handwritten digits 0 to 9 and 10,000 test images. Each image is represented in grayscale and is 28 x 28 pixels in size. This dataset has been widely used as a benchmark to evaluate and compare the performance of different algorithms in the field of handwriting recognition. When used in conjunction with PyTorch, the MNIST dataset serves as a powerful tool for efficiently developing and evaluating handwriting recognition models.

\section* {Data Augmentation}
Data augmentation plays a crucial role in improving the performance of machine learning models in handwriting recognition. Given the inherent variability of human handwriting, robust and diverse datasets are critical for training effective models. Data augmentation involves artificially extending a training data set by creating modified versions of existing data. In handwriting recognition, this can be achieved using various techniques. A common method is geometric transformation, including rotating, scaling and translating images of handwritten text. This teaches the model to recognize characters and words appearing in different orientations and sizes. Another technique involves morphological operations such as eroding or stretching text, simulating different writing pressures and line widths. Adding noise, such as random pixel fluctuations, can also be beneficial as it prepares the model to handle real-world scenarios where handwritten text may be distorted or unclear.

Data Augmentation also contains a subset, called the Color space augmentations. It can be used as adjust the brightness or contrast. These methods are particularly useful for colored ink or paper. The Elastic distortions would warp the image in a non-linear manner, effectively mimic the natural irregularities in handwriting. Further, synthetic data generation, where entirely new handwriting samples are generated using advanced techniques like Generative Adversarial Networks (GANs), offers a way to significantly expand the dataset, especially in scenarios where data collection is challenging or privacy concerns are paramount. These augmentation techniques not only help in creating a more robust model by providing a wide range of handwriting styles and conditions but also aid in reducing over fitting, ensuring that the model generalizes well to new, unseen data. The strategic use of data augmentation in handwriting recognition thus plays a crucial role in enhancing the accuracy and reliability of the resulting machine learning models.

\section* {Algorithms in Handwriting Recognition}
However, collecting and augmenting the data cannot do everything for us, As I mentioned previously, the MNIST dataset contains 60000 for training purposes and 10000 for optimizing the model, we have to choose a relatively credible approach to recognize what the user have written. For approaches, we now have: Traditional Machine Learning Approaches, Neural Network Approaches and Hybrid. Each of them contains various methods and concepts.

\paragraph{Traditional Machine Learning Approaches}
The Traditional Machine Learning Approaches is the most fundamental and a little bit of antiquated way. The most well-known of these is the decision tree. The decision tree belongs to the supervised learning and it can tackle classification and regressions tasks. The process of it looks like a flowchart, and each node on the chart contains the "test result" of the event. Decision trees provide an intuitive way to extract decision rules from data. It can be visualized and is easy to understand, even for people without a technical background. At the same time, it also reveals the structure and patterns in the data, helping us understand how decisions are supported by data. For example, Suppose we have a data set about weather conditions and whether outdoor activities are performed, we can setup several parameters to estimate it, such as "Weather", which contains "Sunny, Cloudy, and Raining"; "Temperature", which contains "Hot, Proper, Cold", and the third parameter called "Do we want to do the outdoor activities" which only includes yes or no. Our goal is to create a decision tree that helps us decide whether to engage in outdoor activities based on weather conditions. On the climax of the tree, is "Do we want to do the outdoor activities", then, in the first layer of the tree, are the parameters of the weather "Sunny, Cloudy, and Windy" And after this layer, we can output the decisions with yes or no. In this case, sunny and cloudy, could be "yes", and "no" for the rainy. And after many layers of iteration, it could finally have the ability of predictions.

Other approaches of Traditional Machine Learning includes:
\begin{itemize}
    \item \textbf{k-nearest neighbors (KNN)}: KNN is a non-parametric method for classification and regression. It is based on a simple principle, which is predict the label of a point by looking at the "k" closest labeled points and taking a majority vote or average. This method is particularly effective in scenarios with irregular decision boundaries.


    \item \textbf{Support vector machines (SVM)}: SVM is very powerful for classification tasks, especially in high-dimensional spaces. They work by finding the hyperplane that best divides the dataset into categories. The ability of SVM to handle large feature spaces and its effectiveness when the number of dimensions exceeds the number of samples makes it a valuable tool in machine learning.

    \item \textbf{Linear regression}: One of the simplest forms of machine learning, mainly used for regression tasks. The goal is to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. The simplicity of linear regression makes it an excellent starting point for predictive modeling.
\end{itemize}
These traditional methods, although overshadowed by the rise of deep learning and neural networks, remain integral in scenarios where interpretability, simplicity, and speed are crucial. They are advantageous in situations with limited data to prevent overfitting and form the backbone of many hybrid approaches, combining strengths of traditional and modern techniques.

\paragraph{Neural Network Approaches}
Although there are many ways to emphasize and implement the machine learning and training process, the most common way that related to neural network could be elaborated like this: For example, if we have a hand-written number, say 7, in this case, how should we let the machine know it is 7? In the MNIST Dataset, all pictures in it are 5 to 5 scaled, which means there are 25 pixels in total. And then we can line them up into a one-dimensional column, and label them 0 if the block or pixel is black, and 1 when this block is white. In order to proceed to the next step, we also need to number them from $X^{0}_{0}$ to $X^{0}_{24}$. The top number refers to the number of layers and the lower number refers to the number of the elements, and in this case, it is refers to every single pixel.Blow is a figure of a complete computing process of handwriting recognition.
\vspace{10pt}
\includegraphics[page = 1, width=\linewidth]{Neural Networks Exemplar.pdf}

Now, the first node in the second layer could be calculated like this: 
\begin{align}
X^1_{0} &= (a^0_{0,0} \times x^0_{0} + b^0_{0,0}) + (a^0_{1,0} \times x^0_{1} + b^0_{1,0}) + \ldots + (a^0_{24,0} \times x^0_{24} + b^0_{24,0}) \\
&= \sum_{i} (a^0_{i,1} \times x^0_{i} + b^0_{i,1})
\end{align}
The letter $a$ and $b$ are the lines here, and the letter i under each X and its parameters refers to the nodes in the previous layer, and the letter j refers to the nodes in the current layer, and similarly, we can also construct the layers of number 2, 3, and 4. And, with the increase of numbers of layers, the formula of the nodes are also extending. The letter k and k+1 refers to the overall layers in this training process, and the parameters, a and b could be arbitrary. The information of the image, spreading across with this formula and finally goes to the last layer of this network. But why there’re 10 results in the final output, the only thing we could image is the probability. This model is to recognize numbers from 0 – 9, so there are only ten possibilities, which just matches the final output. Each output refers to a number. For example, the $P_1$ here refers to the probability of the result is 1. But the parameters between layers, $a$ and $b$ are arbitrary, so, after the calculation from such number of layers, the result should also be arbitrary. Thus, we cannot ensure the probability is from 0 and 1. So, in order to keep the probability is larger than 0, and smaller than 1, we should do some operations. To ensure the probability on the layer of output is larger than 0, smaller than 1 and their sum is 1.

In order to solve this, and let the We will introduce  the mathematical constant to let the probability follow this rule. By putting an e below every X and calculate their values. Therefore, every value will now larger than 0. Then we add them together, then we use the sum as denominator, and we get this formula, the table below shows the relationship.

\begin{table}[h!]
\centering
\resizebox{\textwidth}{!}{% This will scale the table to fit the text width
\begin{tabular}{cccc}
\hline
\( X_0 \) & \( X_1 \) & \(\cdots\) & \( X_n \) \\
\( e^{X_0} \) & \( e^{X_1} \) & \(\cdots\) & \( e^{X_n} \) \\
\( \frac{e^{X_0}}{\sum{e^{X_i}}} \) & \( \frac{e^{X_1}}{\sum{e^{X_i}}} \) & \(\cdots\) & \( \frac{e^{X_n}}{\sum{e^{X_i}}} \) \\
\hline
\end{tabular}
}
\caption{Softmax Normalization}
\label{table:your_label}
\end{table}

As you can see

\section*{Code Elucidation}
The python file in my Code folder represents an examplar of the handwriting recognition in machine learning, the purpose of this file is first, we use all the pictures in MNIST Dataset to train and optimize the model, then it will ramdomly extract several pictures from the MNIST Dataset to see its result of prediction, the code was divided into four parts:
\begin{verbatim}
def __init__(self):
        super().__init__()
        self.fc1 = torch.nn.Linear(28*28, 64)
        self.fc2 = torch.nn.Linear(64, 64)
        self.fc3 = torch.nn.Linear(64, 64)
        self.fc4 = torch.nn.Linear(64, 64)
        self.fc5 = torch.nn.Linear(64, 10)
\end{verbatim}

This is the first paragraph of the code, it defined 5 layers, the first layer fc1 is the input which includes 28 pixels and 64 nodes, and the last layer fc5 contains 10 outputs, and 64 nodes as well. The 64 nodes in layer 2, 3, 4 are used for optimizing and training. And these whole stuff are contained in the "torch.nn.Module" class. 

\begin{verbatim}
     def forward(self, x):
        x = torch.nn.functional.relu(self.fc1(x))
        x = torch.nn.functional.relu(self.fc2(x))
        x = torch.nn.functional.relu(self.fc3(x))
        x = torch.nn.functional.relu(self.fc4(x))
        x = torch.nn.functional.log_softmax(self.fc5(x), dim=1)
        return x
\end{verbatim}

This paragraph just put an ReLu function outside of the layers and that is the activation function of the layer to ensure to produce the real probability. 

\begin{verbatim}
    def get_data_loader(is_train): #Part 1
    to_tensor = transforms.Compose([transforms.ToTensor()])
    data_set = MNIST("", is_train, transform=to_tensor, download=True)
    return DataLoader(data_set, batch_size=20, shuffle=True)
    
def evaluate(test_data, net): #Part 2
    n_correct = 0
    n_total = 0
    with torch.no_grad():
        for (x, y) in test_data:
            outputs = net.forward(x.view(-1, 28*28))
            for i, output in enumerate(outputs):
                if torch.argmax(output) == y[i]:
                    n_correct += 1
                n_total += 1
    return n_correct / n_total
\end{verbatim}

This paragraph was divided into two parts, the first part just import data from previous layers and make an output as a DataLoader, and the second, The evaluate function is used to estimate the accuracy of the recognition. First, we extract the data from the training set, calculate the accuracy of the neural network, and we compare this value to the Dataset. So these are the normal step of doing such operations in machine learning, especially when training models for handwriting recognition. 

\bibliographystyle{plain}
\bibliography{Citations.bib}
\cite{824821}
\cite{NIPS2008_66368270}
\cite{6981034}
\end{document}